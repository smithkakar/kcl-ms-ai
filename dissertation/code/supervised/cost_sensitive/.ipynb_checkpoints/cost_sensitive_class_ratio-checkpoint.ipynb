{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruthfulnessCostSensitiveEstimator:\n",
    "\n",
    "    def __init__(self):\n",
    "        print('Starting Truthfulness Estimator COST-SENSITIVE Version 1.3')\n",
    "        self.user_responses = self.load_survey_data()\n",
    "        \n",
    "        self.user_responses.drop(columns=['Prolific ID'], inplace=True)\n",
    "        \n",
    "        self.reordered_user_responses = self.customise_data()\n",
    "\n",
    "        self.transformed_user_responses = self.discrete_transform()\n",
    "\n",
    "        # self.classification('binary')\n",
    "        self.classification('multi-class')\n",
    "        \n",
    "    def load_survey_data(self):\n",
    "        df = pd.read_csv('All_Responses_Removed.csv')\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def customise_data(self):\n",
    "        data = self.user_responses\n",
    "        data.columns = data.columns.str.replace(r'[\\s\\n\\t ]+', '-')\n",
    "        data.columns = data.columns.str.replace(r'[a-d]-', '-')\n",
    "\n",
    "        demographics_data = data.iloc[:, :8]\n",
    "        demographics_data = demographics_data.reindex(sorted(demographics_data.columns), axis=1)\n",
    "        question_data = data.reindex(sorted(data.columns[8:]), axis=1)\n",
    "        reordered_user_responses = pd.concat([demographics_data, question_data], axis=1)\n",
    "\n",
    "        return reordered_user_responses\n",
    "    \n",
    "\n",
    "    def discrete_transform(self):\n",
    "        data = self.reordered_user_responses\n",
    "        data.loc[data['Age'] <= 17, 'Age'] = 0\n",
    "        data.loc[(data['Age'] > 17) & (data['Age'] <= 24), 'Age'] = 1\n",
    "        data.loc[(data['Age'] > 24) & (data['Age'] <= 34), 'Age'] = 2\n",
    "        data.loc[(data['Age'] > 34) & (data['Age'] <= 44), 'Age'] = 3\n",
    "        data.loc[(data['Age'] > 44) & (data['Age'] <= 54), 'Age'] = 4\n",
    "        data.loc[(data['Age'] > 54) & (data['Age'] <= 64), 'Age'] = 5\n",
    "        data.loc[data['Age'] > 64, 'Age'] = 6\n",
    "\n",
    "        data.loc[data['Online-Presence'] <= 5, 'Online-Presence'] = 0\n",
    "        data.loc[(data['Online-Presence'] > 5) &\n",
    "                (data['Online-Presence'] <= 10), 'Online-Presence'] = 1\n",
    "        data.loc[(data['Online-Presence'] > 10) &\n",
    "                (data['Online-Presence'] <= 15), 'Online-Presence'] = 2\n",
    "        data.loc[(data['Online-Presence'] > 15) &\n",
    "                (data['Online-Presence'] <= 20), 'Online-Presence'] = 3\n",
    "        data.loc[(data['Online-Presence'] > 20) &\n",
    "                (data['Online-Presence'] <= 25), 'Online-Presence'] = 4\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def impute_data(self, data):\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        imputed_data = pd.DataFrame(imp.fit_transform(\n",
    "            data), columns=data.columns, index=data.index)\n",
    "\n",
    "        return imputed_data\n",
    "\n",
    "\n",
    "    def data_transformation(self, data):\n",
    "        scaler = StandardScaler()\n",
    "        standard_data = pd.DataFrame(scaler.fit_transform(\n",
    "            data), columns=data.columns, index=data.index)\n",
    "\n",
    "        transformer = PowerTransformer()\n",
    "        transformed_data = pd.DataFrame(transformer.fit_transform(\n",
    "            standard_data), columns=data.columns, index=data.index)\n",
    "\n",
    "        return scaler, transformer, transformed_data\n",
    "\n",
    "\n",
    "    def data_inverse_transformation(self, scaler_object, transformer_object, data):\n",
    "        inverse_transformed_data = pd.DataFrame(transformer_object.inverse_transform(data),\n",
    "                                                columns=data.columns, index=data.index)\n",
    "        inverse_scaled_data = pd.DataFrame(scaler_object.inverse_transform(inverse_transformed_data),\n",
    "                                        columns=data.columns, index=data.index)\n",
    "\n",
    "        return inverse_scaled_data\n",
    "    \n",
    "    def classification(self, clf_type):\n",
    "        class_weights = {}\n",
    "        class_count = {}\n",
    "        class_count_ratio = {}\n",
    "        important_features = {}\n",
    "        scale_pos_weight = 1\n",
    "\n",
    "        data = self.transformed_user_responses\n",
    "        if clf_type == 'binary':\n",
    "            data.iloc[:, 10:207:4] = (data.iloc[:, 10:207:4] == 7.0)\n",
    "            type(data.iloc)\n",
    "        if clf_type == 'multi-class':\n",
    "            data.iloc[:, 10:207:4] = data.iloc[:, 10:207:4].replace([1.0, 2.0, 3.0], np.float64(0))\n",
    "            data.iloc[:, 10:207:4] = data.iloc[:, 10:207:4].replace([4.0, 5.0, 6.0], np.float64(1))\n",
    "            data.iloc[:, 10:207:4] = data.iloc[:, 10:207:4].replace([7.0], np.float64(2))\n",
    "\n",
    "        question_estimator = {}\n",
    "\n",
    "        relevant_indexes = []\n",
    "        demographics_column_indexes = ['Age', 'Gender', 'IUIPC-Awareness', 'IUIPC-Collection', 'IUIPC-Control',\n",
    "                                    'Online-Presence', 'Personal-Stability', 'Reciprocity']\n",
    "        relevant_indexes.extend(demographics_column_indexes)\n",
    "        \n",
    "        for question_number in range(1, 51):\n",
    "#             print(\"Question No. is: \", question_number)\n",
    "            question = 'Q' + str(question_number).zfill(2)\n",
    "            \n",
    "            question_indexes = []\n",
    "            question_indexes.extend([str(question_number).zfill(2) + '-Effort',\n",
    "                            str(question_number).zfill(2) + '-Relevance',\n",
    "                            str(question_number).zfill(2) + '-Uncomfortable',\n",
    "                            str(question_number).zfill(2) + '-Truthfulness'])\n",
    "            relevant_indexes.extend(question_indexes)\n",
    "\n",
    "            question_label = str(question_number).zfill(2) + '-Truthfulness'\n",
    "\n",
    "            if clf_type == 'binary':\n",
    "                train_data_question, test_data_question = train_test_split(data[relevant_indexes], \n",
    "                stratify=data[question_label], test_size=0.3, random_state=42)\n",
    "            if clf_type == 'multi-class':\n",
    "                cleaned_user_responses = data.loc[:, relevant_indexes].dropna()\n",
    "\n",
    "                train_data_question, test_data_question = train_test_split(cleaned_user_responses,\n",
    "                                                                        stratify=cleaned_user_responses[question_label],\n",
    "                                                                        test_size=0.3, random_state=42)\n",
    "\n",
    "            train_x_question = train_data_question.copy()\n",
    "            if clf_type == 'binary':\n",
    "                train_x_question = self.impute_data(train_x_question)\n",
    "\n",
    "                computed_weights = class_weight.compute_class_weight('balanced', np.unique(train_x_question[question_label]), train_x_question[question_label]).tolist()\n",
    "                class_weights[question] = {0:computed_weights[0], 1:computed_weights[1]}\n",
    "                \n",
    "            if clf_type == 'multi-class':\n",
    "                temp_df = pd.Series(train_x_question[relevant_indexes].groupby\n",
    "                            (by=question_label).size())\n",
    "                class_count[question] = [temp_df.values[0], temp_df.values[1], temp_df.values[2]]\n",
    "                class_count_ratio[question] = [\n",
    "                    round((temp_df.values[0] / len(train_data_question)) * 100, 2),\n",
    "                    round((temp_df.values[1] / len(train_data_question)) * 100, 2),\n",
    "                    round((temp_df.values[2] / len(train_data_question)) * 100, 2)]\n",
    "\n",
    "                computed_weights = class_weight.compute_class_weight('balanced', np.unique(train_x_question[question_label]), train_x_question[question_label]).tolist()\n",
    "                class_weights[question] = [computed_weights[0], computed_weights[1], computed_weights[2]]\n",
    "                \n",
    "\n",
    "#             train_y_question = train_x_question.loc[:, question_label]\n",
    "#             train_x_question.drop(columns=question_label, inplace=True)\n",
    "\n",
    "#             train_scaler_question, train_transformer_question, transformed_train_x_question = \\\n",
    "#                 self.data_transformation(train_x_question)\n",
    "\n",
    "#             rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "#             rf.fit(transformed_train_x_question, train_y_question)\n",
    "\n",
    "#             importances = rf.feature_importances_\n",
    "#             std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "#             indices = np.argsort(importances)[::-1]\n",
    "\n",
    "#             important_features[question] = indices[0:3].tolist()\n",
    "\n",
    "#             featured_train_data = transformed_train_x_question.iloc[:, important_features[question]]\n",
    "#             try:\n",
    "#                 best_estimator, best_estimator_params = self.find_clf_parameters(featured_train_data, \n",
    "#                 train_y_question, class_weights[question], clf_type)\n",
    "#             except ValueError as e:\n",
    "#                 print(\"Value Error: \" + str(e))\n",
    "#                 print('Record skipped.')\n",
    "#                 continue  \n",
    "\n",
    "#             question_estimator[question] = [best_estimator, best_estimator_params]\n",
    "\n",
    "            del relevant_indexes[8:]\n",
    "#         print(pd.DataFrame.from_dict(class_count_ratio, orient='index', columns=['Class-0', 'Class-1', 'Class-2']))\n",
    "        print(pd.DataFrame.from_dict(class_count, orient='index', columns=['Class-0', 'Class-1', 'Class-2']))\n",
    "        print(pd.DataFrame.from_dict(class_weights, orient='index', columns=['Weight-0', 'Weight-1', 'Weight-2']))\n",
    "#         if not os.path.isdir(RESULTS_DIR):\n",
    "#             os.makedirs(RESULTS_DIR)\n",
    "\n",
    "#         filename = os.path.join(\n",
    "#             RESULTS_DIR, clf_type + '_cost_sensitive_estimator_parameters_1.3.txt')\n",
    "\n",
    "#         with open(filename, 'w') as f:\n",
    "#             print(question_estimator, file=f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Truthfulness Estimator COST-SENSITIVE Version 1.3\n",
      "     Class-0  Class-1  Class-2\n",
      "Q01    23.50    17.05    59.45\n",
      "Q02     1.23     2.88    95.88\n",
      "Q03    15.06    10.88    74.06\n",
      "Q04    67.65     8.82    23.53\n",
      "Q05     2.37     6.16    91.47\n",
      "Q06     6.01    13.30    80.69\n",
      "Q07    22.22    15.74    62.04\n",
      "Q08    45.19    20.08    34.73\n",
      "Q09    16.44    17.81    65.75\n",
      "Q10    23.31    16.53    60.17\n",
      "Q11    33.64    18.22    48.13\n",
      "Q12    66.10    11.86    22.03\n",
      "Q13    41.20    17.60    41.20\n",
      "Q14    46.41    15.19    38.40\n",
      "Q15    54.42     9.77    35.81\n",
      "Q16     1.21     5.26    93.52\n",
      "Q17     1.72    24.46    73.82\n",
      "Q18     1.67    10.46    87.87\n",
      "Q19     3.35     7.95    88.70\n",
      "Q20     1.84     8.29    89.86\n",
      "Q21     3.60    17.57    78.83\n",
      "Q22     6.61    29.75    63.64\n",
      "Q23     1.38    10.09    88.53\n",
      "Q24     7.92    19.17    72.92\n",
      "Q25     1.68    11.34    86.97\n",
      "Q26    14.35    35.19    50.46\n",
      "Q27     2.93    20.50    76.57\n",
      "Q28     0.41    10.33    89.26\n",
      "Q29     2.78    15.28    81.94\n",
      "Q30    33.05    16.95    50.00\n",
      "Q31     8.30    33.61    58.09\n",
      "Q32     4.62    21.43    73.95\n",
      "Q33     1.35     9.91    88.74\n",
      "Q34     4.26    32.34    63.40\n",
      "Q35     4.66    31.78    63.56\n",
      "Q36     4.72    19.34    75.94\n",
      "Q37     3.36    20.17    76.47\n",
      "Q38     1.70    10.64    87.66\n",
      "Q39    10.88    41.00    48.12\n",
      "Q40     4.20    34.03    61.76\n",
      "Q41     1.68    23.95    74.37\n",
      "Q42     0.92    21.20    77.88\n",
      "Q43     5.02    29.22    65.75\n",
      "Q44     2.58    11.16    86.27\n",
      "Q45     1.26    34.45    64.29\n",
      "Q46    30.56    18.98    50.46\n",
      "Q47     3.33    14.58    82.08\n",
      "Q48     1.27    13.14    85.59\n",
      "Q49     5.04    26.89    68.07\n",
      "Q50    73.62     8.94    17.45\n",
      "      Weight-0   Weight-1  Weight-2\n",
      "Q01   1.418301   1.954955  0.560724\n",
      "Q02  27.000000  11.571429  0.347639\n",
      "Q03   2.212963   3.064103  0.450094\n",
      "Q04   0.492754   3.777778  1.416667\n",
      "Q05  14.066667   5.410256  0.364421\n",
      "Q06   5.547619   2.505376  0.413121\n",
      "Q07   1.500000   2.117647  0.537313\n",
      "Q08   0.737654   1.659722  0.959839\n",
      "Q09   2.027778   1.871795  0.506944\n",
      "Q10   1.430303   2.017094  0.553991\n",
      "Q11   0.990741   1.829060  0.692557\n",
      "Q12   0.504274   2.809524  1.512821\n",
      "Q13   0.809028   1.894309  0.809028\n",
      "Q14   0.718182   2.194444  0.868132\n",
      "Q15   0.612536   3.412698  0.930736\n",
      "Q16  27.444444   6.333333  0.356421\n",
      "Q17  19.416667   1.362573  0.451550\n",
      "Q18  19.916667   3.186667  0.379365\n",
      "Q19   9.958333   4.192982  0.375786\n",
      "Q20  18.083333   4.018519  0.370940\n",
      "Q21   9.250000   1.897436  0.422857\n",
      "Q22   5.041667   1.120370  0.523810\n",
      "Q23  24.222222   3.303030  0.376511\n",
      "Q24   4.210526   1.739130  0.457143\n",
      "Q25  19.833333   2.938272  0.383253\n",
      "Q26   2.322581   0.947368  0.660550\n",
      "Q27  11.380952   1.625850  0.435337\n",
      "Q28  80.666667   3.226667  0.373457\n",
      "Q29  12.000000   2.181818  0.406780\n",
      "Q30   1.008547   1.966667  0.666667\n",
      "Q31   4.016667   0.991770  0.573810\n",
      "Q32   7.212121   1.555556  0.450758\n",
      "Q33  24.666667   3.363636  0.375635\n",
      "Q34   7.833333   1.030702  0.525727\n",
      "Q35   7.151515   1.048889  0.524444\n",
      "Q36   7.066667   1.723577  0.438923\n",
      "Q37   9.916667   1.652778  0.435897\n",
      "Q38  19.583333   3.133333  0.380259\n",
      "Q39   3.064103   0.812925  0.692754\n",
      "Q40   7.933333   0.979424  0.539683\n",
      "Q41  19.833333   1.391813  0.448211\n",
      "Q42  36.166667   1.572464  0.428008\n",
      "Q43   6.636364   1.140625  0.506944\n",
      "Q44  12.944444   2.987179  0.386401\n",
      "Q45  26.444444   0.967480  0.518519\n",
      "Q46   1.090909   1.756098  0.660550\n",
      "Q47  10.000000   2.285714  0.406091\n",
      "Q48  26.222222   2.537634  0.389439\n",
      "Q49   6.611111   1.239583  0.489712\n",
      "Q50   0.452794   3.730159  1.910569\n"
     ]
    }
   ],
   "source": [
    "cost_sensitive_estimator = TruthfulnessCostSensitiveEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
